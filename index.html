<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Francisco Costela website</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.13.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg bg-secondary text-uppercase fixed-top" id="mainNav">
            <div class="container" >
                <a class="navbar-brand js-scroll-trigger" href="#page-top"></a><button class="navbar-toggler navbar-toggler-right text-uppercase font-weight-bold bg-primary text-white rounded" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">Menu <i class="fas fa-bars"></i></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ml-auto">
                    	 <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#Home">Home</a></li>
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#portfolio">Portfolio</a></li>
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#Publications">Communication</a></li>
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#about">About</a></li>
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#contact">Contact</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead bg-primary text-white text-center" id="Home" style="background-image: url('assets/img/portfolio/covergray.png')">
            <div class="container d-flex align-items-center flex-column" >
                <!-- Masthead Avatar Image--><img class="masthead-avatar mb-5" src="assets/img/avataaars.svg" alt="" /><!-- Masthead Heading-->
                <h1 class="masthead-heading text-uppercase mb-0">Francisco Costela</h1>
                <!-- Icon Divider-->
                <div class="divider-custom">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-database"></i> <i class="fas fa-robot"></i> <i class="fas fa-microscope"></i> <i class="far fa-eye"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Masthead Subheading-->
                <p class="masthead-subheading font-weight-light mb-0">Data Scientist - Machine Learning innovator - Research Programmer - Vision scientist</p>
            </div>
        </header>

        <!-- Portfolio Section-->
        <section class="page-section portfolio" id="portfolio" style="background-image: url('assets/img/portfolio/data2.jpg')">
            <div class="container">
                <!-- Portfolio Section Heading-->
                <h2 class="page-section-heading text-center text-uppercase mb-0" style="color:#eee">My projects</h2>
                <!-- Icon Divider-->
                <div class="divider-custom" >
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon" style="color:#eee><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Portfolio Grid Items-->
                <h2 class="page-section-heading text-center mb-0" style="color:#eee">Machine learning - Highlights</h2><br>
                <div class="row">

                    
                    <!-- Portfolio Item 1-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal1">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-eye fa-2x"></i>
                                <h3> Machine Learning - Gaze prediction</h3></div> 
                            
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/saccade.png" alt="" />
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal8">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-sitemap fa-2x"></i>
                                <h3> Machine Learning - (Unsupervised) Archetypal analysis </h3></div> 
                            
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/archetype.jpg" alt="" />
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal3">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"> <i class="fas fa-car-crash fa-2x"></i>
                                <h3> Machine Learning - Risk detection in driving</h3></div>
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/riskroc.jpg" alt="" />
                        </div>
                    </div>
                    
                </div>
                <h2 class="page-section-heading text-center mb-0" style="color:#eee">Data analysis / NLP</h2><br>
                <div class="row">
                    <div class="col-md-6 col-lg-4">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal6">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"> <i class="fas fa-plus fa-2x"></i>
                                 <h3> Data Analysis - Psychophysics</h3></div>
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/workload.png" alt="" />
                        </div>
                    </div>

                     <!-- Portfolio Item 1-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal7">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-chart-bar fa-2x"></i>
                                <h3> Data Analysis - Rasch analysis</h3></div> 
                            
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/rasch.png" alt="" />
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal0">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-dumbbell fa-2x"></i></i>
                                <h3> Data analysis - Training in low vision</h3></div> 
                            
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/prl.png" alt="" />
                        </div>
                    </div>
                     <!-- Portfolio Item 5-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-md-0">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal5">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"> <i class="fas fa-database fa-2x"></i></i>
                                <h3> Open-source Gaze Database</h3></div>

                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/gazes.jpg" alt="" />
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal10">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-low-vision fa-2x"></i>
                                <h3> Machine Learning - NLP in low vision </h3></div> 
                            
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/nlpva.jpg" alt="" />
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal9">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-brain fa-2x"></i></i></i>
                                <h3> Machine Learning - NLP in Alzheimer's</h3></div> 
                            
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/nlp.jpg" alt="" />
                        </div>
                    </div>
                    
                </div>


                <h2 class="page-section-heading text-center mb-0" style="color:#eee">Computer Vision - Highlights</h2><br>
                <div class="row">
                    
                    
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal12">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-camera-retro fa-2x"></i>

                                <h3> Computer Vision - Gaze-contingent display</h3></div> 
                            
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/ms.jpg" alt="" />
                        </div>
                    </div>
                    <!-- Portfolio Item 1-->
                    
                    <!-- Portfolio Item 2-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal2">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-hands-helping fa-2x"></i>
                                <h3> Computer Vision - Visual aids</h3></div>    
                                
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/guide.jpeg" alt="" />
                        </div>
                    </div>
                    <!-- Portfolio Item 3-->
                    
                    <!-- Portfolio Item 4-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal4">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"> <i class="fas fa-eye-slash fa-2x"></i>
                                <h3> Computer Vision - Blink detection</h3></div>
                            </div>
                            <img class="img-fluid" src="assets/img/portfolio/blink.jpg" alt="" />
                        </div>
                    </div>


                </div>
            </div>
        </section>
        
        <!-- Publications Section-->
        <section class="page-section bg-primary mb-0" id="Publications" style="background-image: url('assets/img/portfolio/page.jpg')">
            <div class="container" style="color:#222">
                <!-- Publications Section Heading-->
                <h2 class="page-section-heading text-center text-uppercase " >Communication</h2>
                <!-- Icon Divider-->
                <div class="divider-custom divider-dark">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-graduation-cap"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Publications Section Content-->
                <div class="row-md-1 text-center">
                    <p><h3><b>Publications</b></h3> 22 peer-reviewed articles. <a class="btn btn-xl btn-outline-dark" href="https://scholar.google.com/citations?user=oMV9QPQAAAAJ/"><i class="ai ai-google-scholar"></i> </a></p>

                     <p><h3><strong>Reviews</strong></h3>27 verified reviews in Publons. <a class="btn btn-xl btn-outline-dark" href="https://publons.com/researcher/1421274/francisco-m-costela/"><i class="ai ai-publons"></i> </a></p>

                    <p><h3><b>International meetings</b></h3> 21 contributions, including ICMLT, ARVO, SFN, VSS, ECVP, ECEM. See my CV for whole list. <a class="btn btn-xl btn-outline-dark" href="assets/img/portfolio/FranciscoCostela-CV.pdf"><i class="ai ai-cv"></i></a></p>

                    <p><h3><strong>Mentoring</strong></h3> I have been a mentor in the IMFAHE Fellowship program for 5 years, mentoring a total of 10 grad students. I have also mentored 5 interns through the International Mentor Program between Spain and the US and 3 in the Graduate Teaching Associate program of School of Life Sciences at Arizona State University. </p> 
                    
                    <p><h3><b>Volunteer work</b></h3> During my PhD, I was a GPSA Volunteer in the program "Ask a biologist".
                    I also volunteered as Spanish Official Helper at the Oxford Language Centre. I was head of the Volunteer Committee of the <a href="http://illusionoftheyear.com/">Best Illusion of the Year Contest</a> for 4 years.
                    
                </div>
                <!-- Publications Section Button-->
                <div class="text-center mt-4">
                   
                
                    

                    <a class="btn btn-xl btn-outline-dark" href="https://www.researchgate.net/profile/Francisco_Costela"><i class="ai ai-researchgate"></i></i> RG Profile</a>

                   
                    

                </div>
            </div>
        </section>

        <!-- Publications Section-->
        <section class="page-section" id="about" style="background-image: url('assets/img/portfolio/travel.jpg')">
            <div class="container">
                <!-- Publications Section Heading-->
                <!--h2 class="page-section-heading text-center text-uppercase">About</h2-->
                <!-- Icon Divider-->
                <!-- Publications Section Content-->
                <div class="row text-center">
					<div class="col-md-6 text-center">
	 					<h2 class="title-text">
	 					Meet <br><span class="decorate">Francisco</span>
	 					</h2>
                        
	 				</div>
	 				<div class="col-md-6 text-left">
	 					<div class="about-text">
	 						<p> 
						Hello, my name is Francisco Costela (or just Fran). <br>
						I have worked in vision science for over a decade, acquiring experience in data science, machine learning, visual psychophysics, eye tracking, biostatistics, and computer vision (video image processing). I have a strong passion to do research and development with new technologies involving machine learning applied to vision and other translational fields.
						<br> <br>
						During my free time, I like to work on my own projects to improve my skills. My big hobbies are traveling - I have lived in 8 cities (Granada, Edinburgh, Madrid, Chicago, Oxford, Seville, Phoenix, and Boston) and everything involving mind puzzles like escape rooms and modern strategy boardgames. I am one of the organizers of a weekly Boardgame Meetup in Boston (check my profile on BoardGameGeek). I am also physically very active - enjoy lifting and practicing Brazilian jiu-jitsu.<br> <br>
						My goal is to provide value to society. <br>
						Data are my pathway towards that goal.
						</p>
	 					
	 					
	 					</div>
	 				</div>



                    <div class="col-lg-4 ml-auto"><p class="lead"> </p></div>
                      <div class="col-md-6 col-lg-4">
                        
                        <img class="img-fluid" src="assets/img/portfolio/worldmap.png" alt="" />

                    </div>
                    
                    <div class="text-center mt-4">
                    	<a class="btn btn-xl btn-outline-dark" href="https://boardgamegeek.com/collection/user/bossman"></i><img class="img-fluid" width="40" height="40" src="assets/img/portfolio/bgg.png" alt="" /></a>
                	</div>
                </div>
               
                
            </div>
        </section>


        <!-- Contact Section-->
        <section class="page-section bg-primary text-white mb-0" id="contact">
            <div class="container">
                <!-- Contact Section Heading-->
                <h2 class="page-section-heading text-center text-uppercase text-secondary mb-0">Contact Me</h2>
                <!-- Icon Divider-->
                <div class="divider-custom">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Contact Section Form-->
                <div class="row text-center">
	                <div class="col-lg-4 mb-5 mb-lg-0">
	                        <h4 class="text-uppercase mb-4">Location</h4>
	                        <p class="lead mb-0">Harvard Medical School <br />Boston, MA, 02114</p>
	                    </div>
	                    
	                    <div class="col-lg-4 mb-5 mb-lg-0">
	                        <h4 class="text-uppercase mb-4">Around the Web</h4>

	                        <a class="btn btn-outline-light btn-social mx-1" href="https://www.linkedin.com/in/francisco-costela/"><i class="fab fa-fw fa-linkedin-in"></i></a>
	                        <a class="btn btn-outline-light btn-social mx-1" href="https://github.com/fcostela"><i class="fab fa-fw fa-github"></i></a>
	                        <a class="btn btn-outline-light btn-social mx-1" href="mailto:francisco.costela@gmail.com"> <i class="fas fa-envelope"></i></a>
	                    </div>    
	                    
						<div class="col-lg-4">
                       		 <h4 class="text-uppercase mb-4">Resume</h4>
                        	 <a class="btn btn-outline-light btn-social mx-1" href="assets/img/portfolio/FranciscoCostela-resume.pdf"> <i class="fas fa-file"></i></a>


                    	</div>

	                    


	                </div>
	            </div>
            </div>
        </section>
     
        <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes)-->
        <div class="scroll-to-top d-lg-none position-fixed">
            <a class="js-scroll-trigger d-block text-center text-white rounded" href="#page-top"><i class="fa fa-chevron-up"></i></a>
        </div>

        <!-- Portfolio Modal 4-->
        <div class="portfolio-modal modal fade" id="portfolioModal0" tabindex="-1" role="dialog" aria-labelledby="portfolioModal0Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal4Label">Computer Vision - Training in Low vision</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-dumbbell"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/prl.png" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">Created a new method to identify the preferred retinal locus (PRL; the peripheral area of the retina used when the fovea is disabled/damaged) used to watch videos by participants with normal vision, blur defocus lenses, and central visual loss (macular degeneration; see image below), as compared to the democratic Center of Interest (gazes from people with normal vision)<br> 
                                    </p>
                                    Also created a perceptual training using a gaze-contingent display with a simulated scotoma to train people with normal vision to develop a PRL and examined their evolution through increasing scotoma sizes. <br><br>

                                    <h6>Github repository</h6> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/PRL-offset"><i class="fab fa-fw fa-github"></i></a><br><br>

                                    <h6>Publication</h6> 
                                    "The Preferred Retinal Locus Used to Watch Videos"<a class="btn btn-outline-dark btn-social mx-1" href="https://iovs.arvojournals.org/article.aspx?articleid=2665422"><i class="fas fa-pen-nib"></i></a><br>
                                    </p>

                                    <img class="img-fluid rounded mb-5" src="https://arvo.silverchair-cdn.com/arvo/content_public/journal/iovs/936622/i1552-5783-58-14-6073-f03.png?Expires=1592072586&Signature=SO0Cc7LfQvSxtTPL4gzYq65HsPLdGKrM-j-4Mw9grIkTdwqeaZjvwdF-aiZfXFtQxsHbZTeR2SH1q4STLitJdX1cz8cpcz8Y~o5kGNt~GmQvveOhXn67TnVXjqGU3F3qbqkiN0c1dtkxppSrngxTVHHgA69mWXzd85ziZyocnpq9~ONebpgf2XNiVDbTIpMIVAe7ER10uKXaGxuX1UzhP-2qb-B2EY9TNtiYhz8R1-m9wBVltB1~-AgwyOZt-AaXZ30wPo9usE9fsXt7LP6Vg9kdJqnqPR3oQiWUXMBb~Ix56RWl2RmBpC-lqSJzA-L2dWeEuFwLhWwOAMI8kzeQDQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">

                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>


        <!-- Portfolio Modals--><!-- Portfolio Modal 1-->
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-labelledby="portfolioModal1Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal1Label">Machine Learning - Gaze prediction </h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-eye"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/saccade.png" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">
                                        A saccade is a fast eye movement that allows the change of visual fixation from one object of interest to another. These movements are characterized by very high angular velocity peaks that can reach up to 1,000º/s, making them as one of the fastest neuromotor activities in the human body. Modeling such a complex movement remains a challenge. Saccadic eye movements can be defined by initial and landing points, duration, amplitude, and velocity profile. The landing point is important as it defines the new fixation region and, therefore, the region of interest of the viewer. Its prediction may reduce problems caused by display-update latency in gaze-contingent systems that make real-time changes in the display based on eye tracking. <br><br>

                                        <b>Neural Network approach</b> ---- The main contribution of this work is to propose the use of state-of-the-art machine learning techniques (i.e., Recurrent Neural Networks) for saccade landing point prediction in real-world scenarios. The proposed method was evaluated using two large datasets including 219,335 human saccades (collected with an EyeLink 1000 system, median 3°, 95% range 1° to 32°) from 75 subjects acquired during viewing video from Hollywood movies. The results obtained using our proposed methods outperform existing approaches with improvements of up to 40% error reduction. The results show that dynamic temporal relationships exploited by Recurrent Neural Networks can improve the performance of traditional Feed Forward Neural Networks<br><br>

                                    <b>Taylor series approach </b>---- Gaze-contingent displays have been widely used in vision research and virtual reality applications. Due to data transmission, image processing, and display preparation, the time delay between the eye tracker and the monitor update may lead to a misalignment between the eye position and the image manipulation during eye movements. I propose a method to reduce the misalignment using a Taylor series to predict the saccadic eye movement. Besides the human saccade dataset, I used data from my electrophysiology experiments (21,844 monkey saccades, collected with a scleral search coil, median 2°, 95% range 1° to 9°). When assuming a 10-ms time delay, the prediction of saccade trajectories using the proposed method could reduce the misalignment greater than two state-of-the-art methods. The average error was about 0.93° for human saccades and 0.26° for monkey saccades. Our results suggest that this proposed saccade prediction method will create more accurate gaze-contingent displays.

                              
                                     <h6>Github repository</h6> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Saccade-prediction"><i class="fab fa-fw fa-github"></i></a><br><br>


                                    <h5>Publications</h5> 
                                    <p class="mb-5">  
                                    "Saccade Landing Point Prediction: A Novel Approach based on Recurrent Neural Networks"
                                    <a class="btn btn-outline-dark btn-social mx-1" href="https://dl.acm.org/doi/abs/10.1145/3231884.3231890"><i class="fas fa-pen-nib"></i></a><br>
                                    "Dynamic gaze-position prediction of saccadic eye movements using a Taylor series"<a class="btn btn-outline-dark btn-social mx-1" href="https://jov.arvojournals.org/article.aspx?articleid=2665187"><i class="fas fa-pen-nib"></i></a><br>
                                    </p>

                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 2-->
        <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-labelledby="portfolioModal2Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal2Label">Computer Vision - Visual aids</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-hands-helping"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/guide.jpeg" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">In these computer vision projects, I computed the Center of Interest by applying a Gaussian Kernel function for each frame based on the gazes of viewers watching videos. I compared the comprehension on video based on different approaches - magnification approach based on democratic COI, static center of image, or random COI. <br><br>
                                    I also created different visual rehabilitation aids for people with central vision loss (macular degeneration) by applying bubble magnification and zoom magnification, and for people with hemianopia using a dynamic cue around the COI (see video below)</p>

                                    <p class="mb-5"> <h6>Video example</h6> <a class="btn btn-outline-dark btn-social mx-1" href="assets/img/portfolio/guide.mov"><i class="fas fa-video"></i></a><br><br>
                              
                                     <h6>Github repository</h6> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Video-edition"><i class="fab fa-fw fa-github"></i></a><br><br>

                                    <h6>Publication</h6> 
                                    "Measuring the Difficulty Watching Video With Hemianopia and an Initial Test of a Rehabilitation Approach"<a class="btn btn-outline-dark btn-social mx-1" href="https://tvst.arvojournals.org/article.aspx?articleid=2697628#195925062"><i class="fas fa-pen-nib"></i></a><br>
                                    </p>

                                    <img class="img-fluid rounded mb-5" src="https://arvo.silverchair-cdn.com/arvo/content_public/journal/tvst/937352/i2164-2591-7-4-13-f01.png?Expires=1592244518&Signature=ElXKn3UDwFvWMpQ16cmxm8wDpdCRaNNGtOHk6RTmVGNPeR-xKDfuShMovw-BK4x6SoGwQA5MJir8XeqCzMn860PH~rrz4yJlu6NzbEEDgXikkbfSOLTyVSlkeV9xEO~RpTFP~V4Ga9GHWPkS45aCYivNU8vOcfGIzxqwKD2qHYVflA8kctnKNIg2IrN51bnFYoY61ySXFNifFSx3lM4-nF2OJAlozqCXpHc279JMMFgxsVyLL1vQy3SMxB3G29Ts4MUVf2aeP8kIPEeen2dfkytAb4mUV20TgAPuJqE-N6Ff4mdbmHCux2QPWzZUh44bw0e1yCcgcm-o7gSeybqKDw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">




                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 3-->
        <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-labelledby="portfolioModal3Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal3Label">Machine Learning - Risk detection in driving</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-car-crash"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/riskroc.jpg" alt="" /><!-- Portfolio Modal - Text-->

                                    <p class="mb-5">I set out to evaluate whether eye movement features extracted from eye tracking data are able to predict risk situations during a risk detection task while watching driving videos. I created predictive models in Python using logistic regressions and feed-forward neural networks.<br><br>

                                    I collected data from thirty-two normally sighted subjects (15 female) who saw 20 clips of recorded driving scenes while their gaze was tracked. They reported when they considered the car should brake anticipating any hazard. <br><br>

                                    All subjects reported at least one major collision hazard in each video (average 3.5 reports). I found that hazard situations were predicted by larger saccades, more and longer fixations, fewer blinks, and a smaller gaze dispersion in both X and Y dimensions. I compared performance between models incorporating a different combination of descriptors with the test equality of receiver operating characteristic areas. Accuracy using feedforward neural networks outperformed logistic regressions. The model including saccadic magnitude, fixation duration, dispersion in x, and pupil returned the highest ROC area under the curve (0.73).</p>

                                    <h6>Github repository</h6> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Risk-prediction"><i class="fab fa-fw fa-github"></i></a><br><br>

                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 4-->
        <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-labelledby="portfolioModal4Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal4Label">Computer Vision - Blink detection</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-eye-slash"></i></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/blink.gif" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">A Matlab program with interface to detect blinks from videos and save the frames automatically. It uses automatic eye detection but can also be disabled to manually indicate the eye region by clicking in the four corners of a rectangle area. The blink detector algorithm is based on a white sclera thresholding method that can be also customised in the interface.</p>

                                    <h6>Github repository</h6> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Blink-detection"><i class="fab fa-fw fa-github"></i></a><br><br>
                                    
                                    <img class="img-fluid rounded mb-5" src="assets/img/portfolio/blinkshot.jpg">

                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 5-->
        <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-labelledby="portfolioModal5Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal5Label">Open-access gaze database</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-database"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/gazes.jpg" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">I created an open-source database of tracked eye movements, collected using an infra-red, video-camera Eyelink 1000 system, from 95 participants as they viewed ‘Hollywood’ video clips. <br>There are 206 clips of 30-s and eleven clips of 30-min for a total viewing time of about 60 hours. The database also provides the raw 30-s video clip files, a short preview of the 30-min clips, and subjective ratings of the content of the videos for each in categories: (1) genre; (2) importance of human faces; (3) importance of human figures; (4) importance of man-made objects; (5) importance of nature; (6) auditory information; (7) lighting; and (8) environment type. Precise timing of the scene cuts within the clips and the democratic gaze scanpath position (center of interest) per frame are provided. <br>At this time, this eye-movement dataset has the widest age range (22–85 years) and is the third largest (in recorded video viewing time) of those that have been made available to the research community. The dataset is freely available in the Open Science Framework repository (link below) and can be used without restriction for educational and research purposes, providing that the paper (link below) is cited in any published work.</p>

                                    <p class="mb-5"> <h6>Video example</h6> <a class="btn btn-outline-dark btn-social mx-1" href="https://ars.els-cdn.com/content/image/1-s2.0-S2352340919303440-mmc1.mp4
                                    "><i class="fas fa-video"></i></a><br><br>
                                    <h6>Database repository</h6><a class="btn btn-outline-dark btn-social mx-1" href="https://osf.io/g64tk/"><i class="fas fa-database"></i></a><br><br>
                                     <h6>Github repository</h6> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Psychophysics---Psychtoolbox"><i class="fab fa-fw fa-github"></i></a><br><br>

                                    <h6>Publication</h6> 
                                    "A free database of eye movements watching “Hollywood” videoclips"<a class="btn btn-outline-dark btn-social mx-1" href="https://www.sciencedirect.com/science/article/pii/S2352340919303440"><i class="fas fa-pen-nib"></i></a><br>
                                    </p>
                                     <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 6-->
        <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-labelledby="portfolioModal6Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal6Label">Data Analysis - Psychophysics</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-desktop"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/workloadorig.jpg" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">I wrote code for multiple psychophysical experiments in Matlab using Psychtoolbox during my career in vision science to measure the role of fixational eye movements in oculomotor control, perception, and cognition. Most of the projects also involved collecting eye movements from eye tracker data (EyeLink 1000).<br>

                                     <h5>Github repository</h5> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Psychophysics---Psychtoolbox"><i class="fab fa-fw fa-github"></i></a><br><br>
                                    <h5>Publications</h5> 
                                    <p class="mb-5">  Task difficulty in mental arithmetic affects microsaccadic rates and magnitudes<a class="btn btn-outline-dark btn-social mx-1" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.12395"><i class="fas fa-pen-nib"></i></a><br>
                                     Microsaccades restore the visibility of minute foveal targets<a class="btn btn-outline-dark btn-social mx-1" href="https://peerj.com/articles/119/"><i class="fas fa-pen-nib"></i></a><br>
                                    Fixational eye movement correction of blink-induced gaze position errors<a class="btn btn-outline-dark btn-social mx-1" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4205003/"><i class="fas fa-pen-nib"></i></a><br>
                                    Changes in visibility as a function of spatial frequency and microsaccade occurrence
                                     errors<a class="btn btn-outline-dark btn-social mx-1" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.13487"><i class="fas fa-pen-nib"></i></a>
                                    </p>

                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 7-->
        <div class="portfolio-modal modal fade" id="portfolioModal7" tabindex="-1" role="dialog" aria-labelledby="portfolioModal7Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal4Label">Data Analysis - Rasch Analysis</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-chart-bar"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/rasch.png" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">There have been few systematic reports of vision-related activity limitations of people with retinitis pigmentosa (RP). I report a merging of data from the National Eye Institute Visual Function Questionnaire (NEI-VFQ) obtained in five previous studies. I asked whether the Vision Function Scale which was developed for cataract patients would apply in this new population (condition).<br><br>

                                    I used data from 594 individuals who completed a total of 1,753 questionnaires, with 209 participants providing responses over at least four years. Rasch analysis showed that the 15-item VFS was poorly targeted. I created a new instrument by adding four driving-related items to the VFS had better targeting. As an indirect validation, VFS-plus person scores were compared to visual field area measured using a Goldmann perimeter, to the summed score for the combined 30-2 and 30/60-1 Humphrey Field Analyzer programs (HFA), to 30-Hz full-field cone electroretinogram (ERG) amplitude, and to ETDRS visual acuity. Changes in VFS-plus person scores with age and between four common heredity groups were also examined. <br><br>

                                    My new model (see image below) had person and item separation of 2.66 and 24.43 respectively. The VFS-plus person scores were related to each vision measure (p<0.001). Over a five-year period, there was a reduction in person scores of 0.5 logits (p<0.001). Person scores fell by an average of 0.34 logits per decade (p<0.0001). Participants with an X-linked hereditary pattern had, on average, lower person scores (p<0.001).  <br><br>

                                    In summary, the VFS-plus instrument quantified a highly-significant annual reduction in perceived vision-related ability over a five-year period, was consistent with clinical measures of vision, and detected lower perceived vision-related ability in participants with X-linked disease. <br><br>

                                    Manuscript submitted.

                                   
                                    <img class="img-fluid rounded mb-5" src="assets/img/portfolio/raschrp.jpg" alt="" />
                                    </p>
                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal9" tabindex="-1" role="dialog" aria-labelledby="portfolioModal9Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal9Label">Machine Learning - NLP in Alzheimer's</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-brain"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/nlp.jpg" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">

                                    I created a new objective measure, the narrative description (ND), of the ability to perceive, understand, and describe a visual scene in a movie clip and used it to assess cognitive status. The process of interpreting and acting upon the visual environment requires both intact cognitive and visual systems. The ND metric uses NLP by comparing the mean number of shared words with a normative dataset after removing stopwords.<br><br>
                                    I used data from 56 participants with cognitive status ranging from normal cognition to mild dementia (median age 82, range 66 to 99 years). They watched 20 30-s video clips and describe the visual content without time constraints. These verbal responses were transcribed and processed to generate ND shared word scores using a “wisdom of the crowd,” natural-language processing approach. I compared ND scores across diagnostic groups, and used linear mixed models to examine decrements in task performance.<br><br>
                                    There was a stepwise decline of ND scores with increasing levels of cognitive impairment. Additional analyses showed that ND performance was highly related to performance on the Montreal Cognitive Assessment (MoCA) and domain-specific neuropsychological tests for semantic fluency and set shifting. Other models demonstrated differences in ND performance related video content between cognitively normal and impaired participants. <br><br> In summary, the ND test was able to detect decrements in task performance between levels of cognitive impairment and was related to other global neuropsychological measures. 

                                   
                                     <h5>Github repository</h5> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/NLP"><i class="fab fa-fw fa-github"></i></a><br><br>
                                    <h5>Publications</h5> 
                                    <p class="mb-5">  "Narrative video scene description task discriminates between levels of cognitive impairment in Alzheimer’s disease""<a class="btn btn-outline-dark btn-social mx-1" href="https://psycnet.apa.org/record/2020-05494-001"><i class="fas fa-pen-nib"></i></a><br>

                                    </p>
                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal10" tabindex="-1" role="dialog" aria-labelledby="portfolioModal10Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal9Label">Machine Learning - NLP in low vision</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-low-vision"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/nlpva.jpg" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">

                                    In these projects, I created a new objective score of information acquisition (IA) derived by comparing each new response to a control database of descriptions of the same clip using natural language processing. I applied this metric to two low vision groups: central vision loss (CVL;macular degeneration) and hemianopia.<br><br>
                                    In the CVL study group, subjects with CVL (n= 23) or normal vision (NV, n= 60) described the content of 30-second video clips from movies and documentaries. We derived an objective information acquisition (IA) score for each response using natural-language processing. To test whether the impact of CVL was simply due to reduced resolution, another group of NV subjects (n= 15) described video clips with defocus blur that reduced visual acuity to 20/50 to 20/800. Mixed models included random effects correcting for differences between subjects and between the clips, with age, gender, cognitive status, and education as covariates.
                                    IA scores were worse for the CVL group (P< 0.001). IA reduced with worsening visual acuity (P< 0.001), and the reduction with worsening visual acuity was greater for the CVL group than the NV-defocus group (P= 0.01), which was seen as a greater discrepancy at worse levels of visual acuity.
                                    Conclusions: The IA method was able to detect difficulties in following the story experienced by people with CVL and HH. 
                                    <br><br>
                                    In the hemianopia (HH) group study, I compared 60 participants with normal vision (NV) to 24 participants with HH to test the hypothesis that participants with HH would score lower than NV participants, consistent with reports from people with HH that describe difficulties in video watching. The HH group had a significantly lower IA score, with an average of 2.8, compared with 4.3 shared words of the NV group (mixed-effects regression, P < 0.001). Presence of the content guide significantly increased the IA score by 0.5 shared words (P = 0.03).<br><br>
                                    
                                   
                                     <h5>Github repository</h5> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Video-audio-description"><i class="fab fa-fw fa-github"></i></a><br><br>
                                    <h5>Publications</h5> 
                                    <p class="mb-5">  "People With Central Vision Loss Have Difficulty Watching Videos""<a class="btn btn-outline-dark btn-social mx-1" href="https://iovs.arvojournals.org/article.aspx?articleid=2723114"><i class="fas fa-pen-nib"></i></a></p>
                                    <p class="mb-5">  "People with Hemianopia Report Difficulty with TV, Computer, Cinema Use, and Photography"<a class="btn btn-outline-dark btn-social mx-1" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5930067/"><i class="fas fa-pen-nib"></i></a><br>
                                    </p>
                                    <p class="mb-5">  "Measuring the Difficulty Watching Video With Hemianopia and an Initial Test of a Rehabilitation Approach"<a class="btn btn-outline-dark btn-social mx-1" href="https://tvst.arvojournals.org/article.aspx?articleid=2697628"><i class="fas fa-pen-nib"></i></a><br>
                                    </p>

                                    


                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>          
            <!-- Portfolio Modal 8-->
        <div class="portfolio-modal modal fade" id="portfolioModal8" tabindex="-1" role="dialog" aria-labelledby="portfolioModal8Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal8Label">Machine Learning - (Unsupervised) Archetypal analysis </h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-sitemap"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/archetype.jpg" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">

                                    I set up to provide objective, numeric descriptors of visual field (VF) patterns from Humphrey Field Analyzer (HFA) data from subjects with retinitis pigmentosa (RP), by using an unsupervised machine learning approach (archetypal analysis). <br><br>
                                    I obtained VFs that were 120-degrees wide from two clinical trials on RP conducted at Massachusetts Eye and Ear Infirmary.  Reliable VFs for up to eight visits and up to 7 years were available for 214 individuals (426 eyes) in Study 1 and 235 individuals (469 eyes) in Study 2. 
                                    I used archetypal analysis to decompose each VF into components that reflected subtypes and affected regions. Each measured VF could be reconstructed from the pattern coefficients. I also examined relationships between archetypal-pattern coefficients and some demographic variables and hereditary-pattern information.<br><br>

                                    I identified eight archetypal patterns in Study 1, and 12 patterns for Study 2 (see figure below) Progressive changes in archetype coefficients, consistent with expectations, were found: archetypes representing a small central VF only (“tunnel vision”) were more related to increasing age, while archetypes with fuller VFs and peripheral islands were less related to increasing age. There were significant differences between hereditary groups in archetype coefficients for many archetypes, indicating that heredity patterns were associated with phenotypes. <br><br>

                                    In summary, archetypal analysis, an unsupervised machine learning method, produced patterns (archetypes) that were descriptive of the variety of VF patterns found in two large samples of people with RP. This is a novel quantitative method of describing VFs in RP. <br><br>
                                    This approach could be used in quantitative analyses, such as genotype-phenotype relationships, or the contribution of peripheral islands to vision-related daily activities, or predicting changes in VF over time or monitoring change, which can be used in evaluations of treatments or inform rehabilitation.<br>
 
                                    <img class="img-fluid rounded mb-5" src="assets/img/portfolio/allarche.jpg" alt="" />
                                    </p>

                                    

                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    <!-- Portfolio Modal 8-->
        <div class="portfolio-modal modal fade" id="portfolioModal12" tabindex="-1" role="dialog" aria-labelledby="portfolioModal12Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true"><i class="fas fa-times"></i></span>
                    </button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0" id="portfolioModal12Label">Computer vision - Gaze-contingent-d</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-camera-retro"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image--><img class="img-fluid rounded mb-5" src="assets/img/portfolio/ms.jpg" alt="" /><!-- Portfolio Modal - Text-->
                                    <p class="mb-5">
                                    I had wide experience simulating low vision impairments using gaze-continget display systems. In the repository, I share the scripts I wrote in Matlab to simulate central vision loss (macular degeneration), hemianopia, and tunnel vision. I have used these methodologies in training programs (check section of PRL training) and also developed gaze-prediction methods to optimize the delay between the eye-tracker and the display system (see section Machine Learning - Gaze prediction). Further, I investigated causes that impact the modeling of saccades based on velocity error and curfature profiles (see paragraph and publication below).<br><br>  
                                    Commonly, saccades are thought to be ballistic eye movements, not modified during flight, with a straight path and a well-described velocity profile. However, they do not always follow a straight path and studies of saccade curvature have been reported previously. In a prior study, I developed a real-time, saccade-trajectory prediction algorithm to improve the updating of gaze-contingent displays and found that saccades with a curved path or that deviated from the expected velocity profile were not well fit by our saccade-prediction algorithm (velocity-profile deviation), and thus had larger updating errors than saccades that had a straight path and had a velocity profile that was fit well by the model. Further, I noticed that the curved saccades and saccades with high velocity-profile deviations were more common than we had expected when participants performed a natural-viewing task. Since those saccades caused larger display updating errors, we sought a better understanding of them. Here we examine factors that could affect curvature and velocity profile of saccades using a pool of 218,744 saccades from 71 participants watching “Hollywood” video clips. <br><br> While viewing the video clips, saccades were most likely horizontal or vertical over oblique. Measured curvature and velocity-profile deviation had continuous, skewed frequency distributions. I used mixed-effects regression models that included cubic terms and found a complex relationship between curvature, velocity-profile deviation and saccade duration (or magnitude). Curvature and velocity-profile deviation were related to some video-dependent features such as lighting, face presence, or nature and human figure content. Time during the session was a predictor for velocity profile deviations. Further, I found a relationship for saccades that were in flight at the time of a scene cut to have higher velocity-profile deviations and lower curvature in univariable models. Saccades characteristics vary with a variety of factors, which suggests complex interactions between oculomotor control and scene content that could be explored further.
 
                                    
                                    </p>

                                     <h5>Github repository</h5> <a class="btn btn-outline-dark btn-social mx-1" href="https://github.com/fcostela/Gaze-contingent-simulations"><i class="fab fa-fw fa-github"></i></a><br><br>
                                    <h5>Publications</h5> 
                                    <p class="mb-5">  "When Watching Video, Many Saccades Are Curved and Deviate From a Velocity Profile Model""<a class="btn btn-outline-dark btn-social mx-1" href="https://www.frontiersin.org/articles/10.3389/fnins.2018.00960/full"><i class="fas fa-pen-nib"></i></a><br><br>

                                    <button class="btn btn-primary" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>


        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Contact form JS-->
        <script src="assets/mail/jqBootstrapValidation.js"></script>
        <script src="assets/mail/contact_me.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
